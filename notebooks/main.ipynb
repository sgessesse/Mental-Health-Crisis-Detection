{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddb6cfe-e431-40af-b332-f0b34fd2fc87",
   "metadata": {},
   "source": [
    "# Mental Health Crisis Detection \n",
    "\n",
    "## Project Overview\n",
    "End-to-end pipeline for detecting suicidal ideation in Reddit posts using BERT. \r\n",
    "Processes raw text data, trains a classification model, and evaluates performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad1d33-3126-45de-8e7f-f8849b47ce05",
   "metadata": {},
   "source": [
    "## Project Pipeline\n",
    "1. **Data Preparation**: Text samples from Reddit Mental Health Dataset\n",
    "2. **Model Training**: Fine-tuned BERT-base with custom dropout layers\n",
    "3. **Evaluation**: Stratified split with 20% test data\n",
    "4. **Deployment**: Saved model package for integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df16f76-e584-438e-b75f-b114da6165ab",
   "metadata": {},
   "source": [
    "## Key Architecture Choices\n",
    "- **BERT-base**: State-of-the-art transformer architecture\n",
    "- **Dynamic Batching**: 256 samples/batch for GPU efficiency\n",
    "- **CUDA Acceleration**: 10x speedup over CPU inference\n",
    "- **Label Encoding**: Maintains class distribution balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036b4cb2-edab-437d-a606-f8ca8ebe8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sem_w\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\sem_w\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Critical dependencies for model operation\n",
    "import import_ipynb # Allows notebook modularization\n",
    "from sklearn.preprocessing import LabelEncoder # Handles class label encoding\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast # BERT components\n",
    "import joblib # Model serialization \n",
    "from preprocess import prepare_data # Data cleaning pipeline\n",
    "from model import train_model # Training workflow\n",
    "from evaluate import evaluate_model # Performance metrics\n",
    "import torch # GPU acceleration\n",
    "import numpy as np # Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bd9b1e-cc9e-4a00-8821-1af411a6f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split dataset with preprocessing\n",
    "X_train, X_test, y_train, y_test=prepare_data(\"../data/reddit_mental_health.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e9551-1f6e-4c80-ae30-a08db871a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model, tokenizer, label_encoder = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b517ec1-6d37-469a-aabb-aa496f0e4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the model\n",
    "save_directory = \"./saved_model2\"\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory) # PyTorch model weights\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory) # Tokenization config\n",
    "\n",
    "# Save the label encoder (optional)\n",
    "joblib.dump(label_encoder, f\"{save_directory}/label_encoder.joblib\")  # Class mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741878a8-6513-46d2-8fac-0e91f1f3df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hardware Configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # GPU preference\n",
    "print(f\"Using device: {device}\") # Verify acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834a94cd-21a1-4378-88ed-46ba0c0083d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory where the model is saved\n",
    "save_directory = \"./saved_model2\"\n",
    "\n",
    "# Reload for inference/testing\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)  # Architecture + weights\n",
    "\n",
    "# ReLoad the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(save_directory) # Text tokenization\n",
    "\n",
    "# ReLoad the label encoder (optional)\n",
    "label_encoder = joblib.load(f\"{save_directory}/label_encoder.joblib\") # Class labels (0: NON-SUICIDAL, 1: SUICIDAL)\n",
    "\n",
    "model.to(device).eval() # Set to inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bd3068-304f-425e-8cad-5c390adcfd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9812833066158313\n",
      "Recall: 0.9792891732964372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9812833066158313, 0.9792891732964372)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance with F1 score and Recall \n",
    "evaluate_model(model, tokenizer, X_test, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bcfb2-14a4-4271-8566-298c820b9d2a",
   "metadata": {},
   "source": [
    "## Performance Highlights\n",
    "- Achieved 98.1% F1 score on test set\n",
    "- 97.9% recall ensures minimal missed at-risk cases\n",
    "- Sub-second inference per batch enables real-time analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a7c91-6784-474b-817d-02f27a34eec4",
   "metadata": {},
   "source": [
    "## Evaluation Insights\n",
    "The near-perfect scores suggest the model is exceptionally effective at:\n",
    "1. Capturing linguistic patterns associated with suicidal ideation\n",
    "2. Maintaining high sensitivity while minimizing false negatives\n",
    "3. Generalizing well to unseen text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e45e8d-25f8-4ea4-9992-fb016842f6b2",
   "metadata": {},
   "source": [
    "## Ethical Considerations\n",
    "While achieving high accuracy, model predictions should:\n",
    "1. Never be used without human review\n",
    "2. Include crisis resources when deployed\n",
    "3. Maintain strict user anonymity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
